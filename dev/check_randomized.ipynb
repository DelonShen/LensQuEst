{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd01c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "IN_DATA_FNAMES = ['/oak/stanford/orgs/kipac/users/delon/LensQuEst/map_sims_%d.pkl'%(i) for i in range(1,51)]\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d077b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "WORKING_DIR = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.insert(1, os.path.join(WORKING_DIR,'LensQuEst'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8221081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from universe import *\n",
    "from halo_fit import *\n",
    "from cmb import *\n",
    "from flat_map import *\n",
    "from weight import *\n",
    "from pn_2d import *\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b176a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map properties\n"
     ]
    }
   ],
   "source": [
    "print(\"Map properties\")\n",
    "\n",
    "# number of pixels for the flat map\n",
    "nX = 300\n",
    "nY = 300\n",
    "\n",
    "# map dimensions in degrees\n",
    "sizeX = 20.\n",
    "sizeY = 20.\n",
    "\n",
    "# basic map object\n",
    "baseMap = FlatMap(nX=nX, nY=nY, sizeX=sizeX*np.pi/180., sizeY=sizeY*np.pi/180.)\n",
    "\n",
    "# multipoles to include in the lensing reconstruction\n",
    "lMin = 30.; lMax = 3.5e3\n",
    "\n",
    "# ell bins for power spectra\n",
    "nBins = 51  # number of bins\n",
    "lRange = (1., 2.*lMax)  # range for power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f44ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/universe_Planck15/camb/CAMB_outputs.pkl\n"
     ]
    }
   ],
   "source": [
    "oup_fname = '../data/input/universe_Planck15/camb/CAMB_outputs.pkl'\n",
    "print(oup_fname)\n",
    "f = open(oup_fname, 'rb') \n",
    "powers,cl,c_lensed,c_lens_response = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "totCL=powers['total']\n",
    "unlensedCL=powers['unlensed_scalar']\n",
    "\n",
    "L = np.arange(unlensedCL.shape[0])\n",
    "\n",
    "unlensedTT = unlensedCL[:,0]/(L*(L+1))*2*np.pi\n",
    "F = unlensedTT\n",
    "funlensedTT = interp1d(L, F, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "L = np.arange(cl.shape[0])\n",
    "PP = cl[:,0]\n",
    "rawPP = PP*2*np.pi/((L*(L+1))**2)\n",
    "rawKK = L**4/4 * rawPP\n",
    "\n",
    "fKK = interp1d(L, rawKK, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "L = np.arange(totCL.shape[0])\n",
    "\n",
    "lensedTT = totCL[:,0]/(L*(L+1))*2*np.pi\n",
    "F = lensedTT\n",
    "flensedTT = interp1d(L, F, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "\n",
    "ftot = lambda l : flensedTT(l) + cmb.fForeground(l) + cmb.fdetectorNoise(l)\n",
    "\n",
    "\n",
    "L = np.arange(c_lens_response.shape[0])\n",
    "\n",
    "cTgradT = c_lens_response.T[0]/(L*(L+1))*2*np.pi\n",
    "\n",
    "fTgradT = interp1d(L, cTgradT, kind='linear', bounds_error=False, fill_value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84118eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29901, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powers['unlensed_scalar'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25c6c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4293a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the lMin and lMax to the assumptions of the analysis\n",
    "# CMB S4/SO specs\n",
    "cmb = StageIVCMB(beam=1.4, noise=7., lMin=lMin, lMaxT=lMax, lMaxP=lMax, atm=False)\n",
    "\n",
    "# Total power spectrum, for the lens reconstruction\n",
    "# basiscally gets what we theoretically expect the\n",
    "# power spectrum will look like\n",
    "forCtotal = lambda l: ftot(l) \n",
    "\n",
    "# reinterpolate: gain factor 10 in speed\n",
    "L = np.logspace(np.log10(lMin/2.), np.log10(2.*lMax), 1001, 10.)\n",
    "F = np.array(list(map(forCtotal, L)))\n",
    "cmb.fCtotal = interp1d(L, F, kind='linear', bounds_error=False, fill_value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df5ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gets a theoretical prediction for the noise\n",
      "computing the reconstruction noise\n"
     ]
    }
   ],
   "source": [
    "print(\"Gets a theoretical prediction for the noise\")\n",
    "fNqCmb_fft = baseMap.forecastN0Kappa(fTgradT, cmb.fCtotal, lMin=lMin, lMax=lMax, test=False)\n",
    "Ntheory = lambda l: fNqCmb_fft(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6702ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data = {}\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c133f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The number of `values` elements must match the length of each `sample` dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19611/4013150662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mc_ps_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mc_ps_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mc_ps_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_ps_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_ps_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpowerSpectrum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFourier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqrtNhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnBins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnBins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mck\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mps_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_ps_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LensQuEst/LensQuEst/flat_map.py\u001b[0m in \u001b[0;36mpowerSpectrum\u001b[0;34m(self, dataFourier, theory, theory_l, fsCl, nBins, lRange, plot, name, save, notGaussian)\u001b[0m\n\u001b[1;32m    510\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdataFourier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m          \u001b[0mdataFourier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFourier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossPowerSpectrum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFourier1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataFourier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataFourier2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataFourier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheory_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheory_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfsCl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfsCl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnBins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnBins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlRange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlRange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotGaussian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotGaussian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LensQuEst/LensQuEst/flat_map.py\u001b[0m in \u001b[0;36mcrossPowerSpectrum\u001b[0;34m(self, dataFourier1, dataFourier2, theory, theory_l, fsCl, nBins, lRange, plot, name, save, notGaussian)\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0mpower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataFourier1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFourier2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       \u001b[0mpower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unnecessary in principle, but avoids binned_statistics to complain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mCl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlEdges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinned_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlEdges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m       \u001b[0mCl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0;31m# finite volume correction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/scipy/stats/_binned_statistic.py\u001b[0m in \u001b[0;36mbinned_statistic\u001b[0;34m(x, values, statistic, bins, range)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mrange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     medians, edges, binnumbers = binned_statistic_dd(\n\u001b[0m\u001b[1;32m    185\u001b[0m         [x], values, statistic, bins, range)\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/scipy/stats/_binned_statistic.py\u001b[0m in \u001b[0;36mbinned_statistic_dd\u001b[0;34m(sample, values, statistic, bins, range, expand_binnumbers, binned_statistic_result)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;31m# Make sure `values` match `sample`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatistic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'count'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mVlen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDlen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         raise AttributeError('The number of `values` elements must match the '\n\u001b[0m\u001b[1;32m    572\u001b[0m                              'length of each `sample` dimension.')\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The number of `values` elements must match the length of each `sample` dimension."
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    [-1, -1], #lensed\n",
    "    [-2, -2], #GRF\n",
    "    [-3, -3]  #randomized phase\n",
    "]\n",
    "data_names = {\n",
    "    0: 'cmb0F_1',\n",
    "    1: 'lCmbF_o1_1',\n",
    "    2: 'lCmbF_o2_1',\n",
    "    3: 'lCmbF_o3_1',\n",
    "    4: 'lCmbF_o4_1',\n",
    "    -1: 'lCmbF_1',\n",
    "    -2: 'totalF_0',\n",
    "}\n",
    "\n",
    "# pbar = trange(len(pairs))\n",
    "for file_idx in trange(1,51): \n",
    "    for pair_idx in range(len(pairs)):\n",
    "        pair = pairs[pair_idx]\n",
    "        c_fname = '/oak/stanford/orgs/kipac/users/delon/LensQuEst/estimators_FILE%d_pair_%d_%d.pkl'%(file_idx, pair[0], pair[1])\n",
    "        if(not os.path.isfile(c_fname)):\n",
    "            continue\n",
    "        f = open(c_fname, 'rb')  \n",
    "        c_data = pickle.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        pair_things = '%d%d'%(pair[0],pair[1])\n",
    "        ck = pair_things\n",
    "        for data_idx in range(len(c_data['%s_sqrtN'%(pair_things)])):\n",
    "            sqrtNhat = c_data['%s_sqrtN'%(pair_things)][data_idx]\n",
    "\n",
    "            c_ps_data = {}\n",
    "            c_ps_data[ck] = [0,0,0]\n",
    "            c_ps_data[ck][0], c_ps_data[ck][1], c_ps_data[ck][2] = baseMap.powerSpectrum(dataFourier=sqrtNhat, nBins=nBins)\n",
    "            if(ck not in ps_data.keys()):\n",
    "                ps_data[ck] = np.array([c_ps_data[ck]])\n",
    "            else:\n",
    "                ps_data[ck] = np.vstack((ps_data[ck],np.array([c_ps_data[ck]])))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #estimate Nhat\n",
    "# ck = 'Nhat'\n",
    "# for data_idx in trange(len(data['-1-1_sqrtN'])):\n",
    "#     sqrtNhat = data['-1-1_sqrtN'][data_idx]\n",
    "    \n",
    "#     c_ps_data = {}\n",
    "#     c_ps_data[ck] = [0,0,0]\n",
    "#     c_ps_data[ck][0], c_ps_data[ck][1], c_ps_data[ck][2] = baseMap.powerSpectrum(dataFourier=sqrtNhat, nBins=nBins)\n",
    "#     if(ck not in ps_data.keys()):\n",
    "#         ps_data[ck] = np.array([c_ps_data[ck]])\n",
    "#     else:\n",
    "#         ps_data[ck] = np.vstack((ps_data[ck],np.array([c_ps_data[ck]])))  \n",
    "        \n",
    "# print(ps_data[ck].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #estimate GRF Nhat\n",
    "# ck = 'GRF'\n",
    "# for data_idx in trange(len(data['-2-2_sqrtN'])):\n",
    "#     sqrtNhat = data['-2-2_sqrtN'][data_idx]\n",
    "    \n",
    "#     c_ps_data = {}\n",
    "#     c_ps_data[ck] = [0,0,0]\n",
    "#     c_ps_data[ck][0], c_ps_data[ck][1], c_ps_data[ck][2] = baseMap.powerSpectrum(dataFourier=sqrtNhat, nBins=nBins)\n",
    "#     if(ck not in ps_data.keys()):\n",
    "#         ps_data[ck] = np.array([c_ps_data[ck]])\n",
    "#     else:\n",
    "#         ps_data[ck] = np.vstack(( ps_data[ck], np.array([c_ps_data[ck]])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #estimate GRF Nhat\n",
    "# ck = 'GRF random'\n",
    "# for data_idx in trange(len(data['-3-3_sqrtN'])):\n",
    "#     sqrtNhat = data['-3-3_sqrtN'][data_idx]\n",
    "    \n",
    "#     c_ps_data = {}\n",
    "#     c_ps_data[ck] = [0,0,0]\n",
    "#     c_ps_data[ck][0], c_ps_data[ck][1], c_ps_data[ck][2] = baseMap.powerSpectrum(dataFourier=sqrtNhat, nBins=nBins)\n",
    "#     if(ck not in ps_data.keys()):\n",
    "#         ps_data[ck] = np.array([c_ps_data[ck]])\n",
    "#     else:\n",
    "#         ps_data[ck] = np.vstack(( ps_data[ck], np.array([c_ps_data[ck]])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ck = 'QEQE'\n",
    "# for data_idx in trange(len(data['-1-1'])):\n",
    "#     sqrtNhat = data['-1-1'][data_idx]\n",
    "    \n",
    "#     c_ps_data = {}\n",
    "#     c_ps_data[ck] = [0,0,0]\n",
    "#     c_ps_data[ck][0], c_ps_data[ck][1], c_ps_data[ck][2] = baseMap.powerSpectrum(dataFourier=sqrtNhat, nBins=nBins)\n",
    "#     if(ck not in ps_data.keys()):\n",
    "#         ps_data[ck] = np.array([c_ps_data[ck]])\n",
    "#     else:\n",
    "#         ps_data[ck] = np.vstack((ps_data[ck],np.array([c_ps_data[ck]])))  \n",
    "        \n",
    "# print(ps_data[ck].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c84268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LBinned, NtheoryBinned = baseMap.binTheoryPowerSpectrum(Ntheory, nBins=nBins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LBinned, fKKBinned = baseMap.binTheoryPowerSpectrum(fKK, nBins=nBins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_Cl(Cls_tot):\n",
    "    n_runs = np.shape(Cls_tot)[0]\n",
    "    print(n_runs, np.shape(Cls_tot))\n",
    "    lCen = Cls_tot[0][0]\n",
    "    \n",
    "    Cls = np.mean(Cls_tot[:,1,:], axis=0)\n",
    "    sCls = np.std(Cls_tot[:,1,:], axis=0)/np.sqrt(n_runs)\n",
    "\n",
    "    return lCen, Cls, sCls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=0.01\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize =(12,8))\n",
    "\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 32\n",
    "\n",
    "ell = baseMap.l.flatten()\n",
    "\n",
    "lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['-1-1']))\n",
    "lCen1, Cl1, sCl1 = LBinned, NtheoryBinned, np.zeros_like(sCl0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print((Cl0-Cl1)/Cl0)\n",
    "assert(all(lCen0 == lCen1))\n",
    "ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "            fmt='o-', capsize=3, capthick=1, c='red', label=r'$\\hat N$ on Lensed Maps')#, label=labels[key], c=colors[key])\n",
    "\n",
    "tmp = [l*np.exp(offset*1)-l for l in lCen0]\n",
    "\n",
    "\n",
    "lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['-3-3']))\n",
    "ax.errorbar(lCen0+tmp, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "            fmt='x-', capsize=3, capthick=1, c='blue', label=r'$\\hat N$ on $T_\\ell = \\sqrt{C_\\ell^{\\rm tot}} e^{i\\phi_\\ell^{\\rm random}}$')#, label=labels[key], c=colors[key])\n",
    "\n",
    "\n",
    "tmp = [l*np.exp(offset*2)-l for l in lCen0]\n",
    "\n",
    "lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['-2-2']))\n",
    "ax.errorbar(lCen0+tmp, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "            fmt='x-', capsize=3, capthick=1, c='Green', label=r'$\\hat N$ on GRF')#, label=labels[key], c=colors[key])\n",
    "\n",
    "# lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF havled']))\n",
    "# ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "#             fmt='x-', capsize=3, capthick=1, c='lightgreen', label=r'$\\hat N$ on GRF [Halved Stats]')#, label=labels[key], c=colors[key])\n",
    "\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(r'$\\ell$')\n",
    "ax.set_ylabel(r'$\\frac{\\hat N-N_{\\rm theory}}{N_{\\rm theory}}$')\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xlim(lMin,2*lMax)\n",
    "# ax.set_ylim(1.1e-10,.9e-3)\n",
    "\n",
    "ax.fill_between([0, 1e20], [-0.001, -0.001], [0.001, 0.001], alpha=1, color='0.95')#, label=r'$<1\\%$ Error')\n",
    "\n",
    "# ax.set_yscale('symlog', linthresh=.5e-2) \n",
    "\n",
    "ax.axhline(0, c='k')\n",
    "\n",
    "ax.set_ylim(-.25e-2, .25e-2)\n",
    "ax.set_xlim(32, 3000)\n",
    "ax.set_yticks([-0.001,- 0.002,0.001, 0.002])\n",
    "ax.legend(frameon=False)\n",
    "# ax.set_yticks([-1e-1,-1e-2,-1e-3,1e-1,1e-2,1e-3])\n",
    "# plt.savefig('figures/Nhat various.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offset=0.03\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize =(12,8))\n",
    "\n",
    "\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "# plt.rcParams['font.size'] = 20\n",
    "\n",
    "# ell = baseMap.l.flatten()\n",
    "\n",
    "# lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['QEQE']))\n",
    "# lCen1, Cl1, sCl1 = LBinned, NtheoryBinned, np.zeros_like(sCl0)\n",
    "\n",
    "\n",
    "# # print((Cl0-Cl1)/Cl0)\n",
    "# assert(all(lCen0 == lCen1))\n",
    "# ax.errorbar(lCen0, Cl0, yerr=sCl0, alpha=0.75, \n",
    "#             fmt='o-', capsize=3, capthick=1, c='red', label=r'QEQE')#, label=labels[key], c=colors[key])\n",
    "\n",
    "\n",
    "\n",
    "# lCen1, Cl1, sCl1 = LBinned, fKKBinned, np.zeros_like(fKK)\n",
    "# ax.errorbar(lCen1, Cl1, yerr=sCl1, alpha=0.75, \n",
    "#             fmt='o-', capsize=3, capthick=1, c='black', label=r'KK')#, label=labels[key], c=colors[key])\n",
    "\n",
    "# # tmp = [l*np.exp(offset*1)-l for l in lCen0]\n",
    "\n",
    "\n",
    "# # lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF random']))\n",
    "# # ax.errorbar(lCen0+tmp, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "# #             fmt='x-', capsize=3, capthick=1, c='blue', label=r'$\\hat N$ on $T_\\ell = \\sqrt{C_\\ell^{\\rm tot}} e^{i\\phi_\\ell^{\\rm random}}$')#, label=labels[key], c=colors[key])\n",
    "\n",
    "\n",
    "# # tmp = [l*np.exp(offset*2)-l for l in lCen0]\n",
    "\n",
    "# # lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF']))\n",
    "# # ax.errorbar(lCen0+tmp, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "# #             fmt='x-', capsize=3, capthick=1, c='Green', label=r'$\\hat N$ on GRF')#, label=labels[key], c=colors[key])\n",
    "\n",
    "# # lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF havled']))\n",
    "# # ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "# #             fmt='x-', capsize=3, capthick=1, c='lightgreen', label=r'$\\hat N$ on GRF [Halved Stats]')#, label=labels[key], c=colors[key])\n",
    "\n",
    "\n",
    "# ax.legend(frameon=False)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_xlabel(r'$\\ell$')\n",
    "# ax.set_ylabel(r'$\\frac{\\hat N-N_{\\rm theory}}{N_{\\rm theory}}$')\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xlim(lMin,2*lMax)\n",
    "# ax.set_ylim(1.1e-10,.9e-3)\n",
    "\n",
    "# # ax.fill_between([0, 1e20], [-0.1, -0.1], [0.1, 0.1], alpha=1, color='0.95')#, label=r'$<10\\%$ Error')\n",
    "# # ax.fill_between([0, 1e20], [-0.01, -0.01], [0.01, 0.01], alpha=1, color='0.85')#, label=r'$<1\\%$ Error')\n",
    "# ax.fill_between([0, 1e20], [-0.001, -0.001], [0.001, 0.001], alpha=1, color='0.75')#, label=r'$<1\\%$ Error')\n",
    "\n",
    "# # ax.set_yscale('symlog', linthresh=.5e-2) \n",
    "\n",
    "# ax.axhline(0, c='k')\n",
    "\n",
    "# ax.set_ylim(-.98e-2, .98e-2)\n",
    "# ax.set_xlim(42, 3000)\n",
    "# ax.legend(frameon=False)\n",
    "# # ax.set_yticks([-1e-1,-1e-2,-1e-3,1e-1,1e-2,1e-3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_norm = baseMap.computeQuadEstPhiNormalizationFFT(fTgradT, cmb.fCtotal)\n",
    "\n",
    "tmp_norm = np.real(tmp_norm)\n",
    "# remove the nans\n",
    "tmp_norm = np.nan_to_num(tmp_norm)\n",
    "# make sure every value is positive\n",
    "tmp_norm = np.abs(tmp_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnorm, normps, _ = baseMap.powerSpectrum(tmp_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnorm = interp1d(lnorm, normps, kind='linear', bounds_error=False, fill_value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnorm = baseMap.forecastN0Kappa(fTgradT, cmb.fCtotal, lMin=lMin, lMax=lMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L, np.array(list(map(fnorm, L))), label='norm')\n",
    "plt.plot(L, list(map(Ntheory,L)),label='ntheory')\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim([7e-8,1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L, list(map(flensedTT, L)))\n",
    "plt.plot(L, list(map(ftot,L)))\n",
    "plt.plot(L, list(map(fTgradT,L)))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e399c9",
   "metadata": {},
   "source": [
    "We showed in the paper tthat Nhat(GRF) should be biased by\n",
    "$${\\rm correction} = 2 N_{\\rm theory}^2 F_{L/2, L/2}^2 (C_{L/2}^{\\rm tot})^2$$\n",
    "\n",
    "$$F_{L/2, L/2} = \\frac{f_{L/2, L/2}}{2 (C_{L/2}^{\\rm tot})^2}$$\n",
    "$$f_{L/2, L/2} = 2/(L)^2 \\times (L)\\cdot L C_{L/2}^{T\\nabla T}=2 C_{L/2}^{T\\nabla T}$$\n",
    "\n",
    "$$F_{L/2, L/2} = \\frac{ C_{L/2}^{T\\nabla T}}{ (C_{L/2}^{\\rm tot})^2}$$\n",
    "\n",
    "$${\\rm correction} = 2 N_{\\rm theory}^2 \\times  \\frac{(C_{L/2}^{T\\nabla T})^2}{ (C_{L/2}^{\\rm tot})^2}  $$\n",
    "EDIT: IGNORE AND SEE PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = lambda L: 1/2*fnorm(L)**2*fTgradT(L/2)**2 / ftot(L/2)**2  * 1/(baseMap.sizeX * baseMap.sizeY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96db05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=0\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize =(16,10))\n",
    "\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "ell = baseMap.l.flatten()\n",
    "\n",
    "lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['Nhat']))\n",
    "lCen1, Cl1, sCl1 = LBinned, NtheoryBinned, np.zeros_like(sCl0)\n",
    "\n",
    "\n",
    "\n",
    "# print((Cl0-Cl1)/Cl0)\n",
    "assert(all(lCen0 == lCen1))\n",
    "ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "            fmt='o-', capsize=3, capthick=1, c='red', label=r'$\\hat N$ on \"Real\" Data')#, label=labels[key], c=colors[key])\n",
    "\n",
    "\n",
    "\n",
    "lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF random']))\n",
    "ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "            fmt='x-', capsize=3, capthick=1, c='blue', label=r'$\\hat N$ on $T_\\ell = \\sqrt{C_\\ell^{\\rm tot}} e^{i\\phi_\\ell^{\\rm random}}$')#, label=labels[key], c=colors[key])\n",
    "\n",
    "lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF']))\n",
    "ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "            fmt='x-', capsize=3, capthick=1, c='Green', label=r'$\\hat N$ on GRF')#, label=labels[key], c=colors[key])\n",
    "\n",
    "# lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF havled']))\n",
    "# ax.errorbar(lCen0, (Cl0-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "#             fmt='x-', capsize=3, capthick=1, c='lightgreen', label=r'$\\hat N$ on GRF [Halved Stats]')#, label=labels[key], c=colors[key])\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(r'$\\ell$')\n",
    "ax.set_ylabel(r'$\\frac{\\hat N-N_{\\rm theory}}{N_{\\rm theory}}$')\n",
    "\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xlim(lMin,2*lMax)\n",
    "# ax.set_ylim(1.1e-10,.9e-3)\n",
    "\n",
    "# ax.fill_between([0, 1e20], [-0.1, -0.1], [0.1, 0.1], alpha=1, color='0.95')#, label=r'$<10\\%$ Error')\n",
    "# ax.fill_between([0, 1e20], [-0.01, -0.01], [0.01, 0.01], alpha=1, color='0.85')#, label=r'$<1\\%$ Error')\n",
    "ax.fill_between([0, 1e20], [-0.001, -0.001], [0.001, 0.001], alpha=1, color='0.85')#, label=r'$<1\\%$ Error')\n",
    "\n",
    "\n",
    "corr = np.array(list(map(correction, lCen0)))\n",
    "# print((corr)/Cl1)\n",
    "# plt.scatter(lCen0, (16)*(corr)/Cl1, label=r'correction $\\times$ 16', c='purple', s=10)\n",
    "plt.scatter(lCen0, (corr)/Cl1, label='correction', c='k', s=10)\n",
    "# print((corr)/Cl1)\n",
    "# plt.scatter(lCen0, (2*np.pi)**2/2*(corr)/Cl1, label=r'correction $\\times (2\\pi)^2/2$', c='pink', s=10)\n",
    "\n",
    "\n",
    "# lCen0, Cl0, sCl0 = combine_Cl(np.array(ps_data['GRF']))\n",
    "# ax.errorbar(lCen0, (Cl0-16*corr-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "#             fmt='x-', capsize=3, capthick=1, c='purple', label=r'$\\hat N$ on GRF $-16\\times$Correction')#, label=labels[key], c=colors[key])\n",
    "# ax.errorbar(lCen0, (Cl0-(2*np.pi)**2/2*corr-Cl1)/(Cl1), yerr=sCl0/Cl1, alpha=0.75, \n",
    "#             fmt='x-', capsize=3, capthick=1, c='pink', label=r'$\\hat N$ on GRF $-(2\\pi)^2/2\\times$Correction')#, label=labels[key], c=colors[key])\n",
    "\n",
    "# ax.set_yscale('symlog', linthresh=.5e-2) \n",
    "\n",
    "ax.axhline(0, c='k')\n",
    "\n",
    "ax.set_ylim(-.98e-2, .98e-2)\n",
    "ax.legend(frameon=False)\n",
    "# ax.set_yticks([-1e-1,-1e-2,-1e-3,1e-1,1e-2,1e-3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4d6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nblensing",
   "language": "python",
   "name": "nblensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
