{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5898cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/input/universe_Planck15/camb/CAMB_outputs.pkl\n",
      "Map properties\n",
      "CMB experiment properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [02:08<01:28,  5.21s/it]"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import os, sys\n",
    "WORKING_DIR = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.insert(1, os.path.join(WORKING_DIR,'LensQuEst'))\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "from universe import *\n",
    "from halo_fit import *\n",
    "from cmb import *\n",
    "from flat_map import *\n",
    "from weight import *\n",
    "from pn_2d import *\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "#######\n",
    "IN_DATA_FNAMES = ['/oak/stanford/orgs/kipac/users/delon/LensQuEst/map_sims_800x800_20x20_%d.pkl'%(i) for i in range(1,51)]\n",
    "\n",
    "\n",
    "pairs = [\n",
    "#   [0,0], #N0\n",
    "#   [0,1], #kappa\n",
    "#   [1,0], #kappa\n",
    "#   [0,2], #N1\n",
    "#   [1,1], #N1\n",
    "#   [2,0], #N1\n",
    "#    [0,3], #should vanish\n",
    "#    [1,2], #should vanish\n",
    "#    [2,1], #should vanish\n",
    "#    [3,0], #should vanish\n",
    "#    [0,4], #N2 \n",
    "#    [1,3], #N2\n",
    "#    [2,2], #N2\n",
    "#    [3,1], #N2\n",
    "#    [4,0], #N2\n",
    "   [-1, -1], #QE\n",
    "   [-2, -2], #unlensed\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#####\n",
    "\n",
    "oup_fname = '../data/input/universe_Planck15/camb/CAMB_outputs.pkl'\n",
    "print(oup_fname)\n",
    "f = open(oup_fname, 'rb') \n",
    "powers,cl,c_lensed,c_lens_response = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "totCL=powers['total']\n",
    "unlensedCL=powers['unlensed_scalar']\n",
    "\n",
    "L = np.arange(unlensedCL.shape[0])\n",
    "\n",
    "unlensedTT = unlensedCL[:,0]/(L*(L+1))*2*np.pi\n",
    "F = unlensedTT\n",
    "funlensedTT = interp1d(L, F, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "L = np.arange(cl.shape[0])\n",
    "PP = cl[:,0]\n",
    "rawPP = PP*2*np.pi/((L*(L+1))**2)\n",
    "rawKK = L**4/4 * rawPP\n",
    "\n",
    "fKK = interp1d(L, rawKK, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "L = np.arange(totCL.shape[0])\n",
    "\n",
    "lensedTT = totCL[:,0]/(L*(L+1))*2*np.pi\n",
    "F = lensedTT\n",
    "flensedTT = interp1d(L, F, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "\n",
    "ftot = lambda l : flensedTT(l) + cmb.fForeground(l) + cmb.fdetectorNoise(l)\n",
    "\n",
    "\n",
    "L = np.arange(c_lens_response.shape[0])\n",
    "\n",
    "cTgradT = c_lens_response.T[0]/(L*(L+1))*2*np.pi\n",
    "\n",
    "fTgradT = interp1d(L, cTgradT, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "print(\"Map properties\")\n",
    "\n",
    "# number of pixels for the flat map\n",
    "nX = 800\n",
    "nY =800\n",
    "\n",
    "# map dimensions in degrees\n",
    "sizeX = 20.\n",
    "sizeY = 20.\n",
    "\n",
    "# basic map object\n",
    "baseMap = FlatMap(nX=nX, nY=nY, sizeX=sizeX*np.pi/180., sizeY=sizeY*np.pi/180.)\n",
    "\n",
    "# multipoles to include in the lensing reconstruction\n",
    "lMin = 30.; lMax = 3.5e3\n",
    "\n",
    "# ell bins for power spectra\n",
    "nBins = 21  # number of bins\n",
    "lRange = (1., 2.*lMax)  # range for power spectra\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "print(\"CMB experiment properties\")\n",
    "\n",
    "# Adjust the lMin and lMax to the assumptions of the analysis\n",
    "# CMB S3 specs\n",
    "cmb = StageIVCMB(beam=1.4, noise=7., lMin=lMin, lMaxT=lMax, lMaxP=lMax, atm=False)\n",
    "\n",
    "# Total power spectrum, for the lens reconstruction\n",
    "# basiscally gets what we theoretically expect the\n",
    "# power spectrum will look like\n",
    "forCtotal = lambda l: ftot(l) \n",
    "\n",
    "# reinterpolate: gain factor 10 in speed\n",
    "L = np.logspace(np.log10(lMin/2.), np.log10(2.*lMax), 1001, 10.)\n",
    "F = np.array(list(map(forCtotal, L)))\n",
    "cmb.fCtotal = interp1d(L, F, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "\n",
    "in_data = {}\n",
    "\n",
    "for fname in tqdm(IN_DATA_FNAMES):\n",
    "    f = open(fname, 'rb') \n",
    "    c_in_data = pickle.load(f) \n",
    "    f.close()\n",
    "    for key in c_in_data:\n",
    "        if(key not in in_data.keys()):\n",
    "            in_data[key] = np.array(c_in_data[key])\n",
    "        else:\n",
    "            in_data[key] = np.vstack( (in_data[key],np.array(c_in_data[key])) )\n",
    "\n",
    "\n",
    "for key in in_data:\n",
    "    print(key, np.shape(in_data[key]))\n",
    "    \n",
    "    \n",
    "pairs = [\n",
    "    [0,0], #N0\n",
    "    [0,1], #kappa\n",
    "    [1,0], #kappa\n",
    "    [1,1], #N1\n",
    "    [0,2], #N1\n",
    "    [2,0], #N1\n",
    "    [-1, -1], #QE\n",
    "    [-2, -2], #unlensed\n",
    "]\n",
    "\n",
    "data_names = {\n",
    "    0: 'cmb0F_1',\n",
    "    1: 'lCmbF_o1_1',\n",
    "    2: 'lCmbF_o2_1',\n",
    "    -1: 'lCmbF_1',\n",
    "    -2: 'totalF_0',\n",
    "}\n",
    "\n",
    "\n",
    "ps_data = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9494e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## kappa_fixed = baseMap.genGRF(fKK, test=False)\n",
    "\n",
    "\n",
    "# TkTkps = []\n",
    "# TkpTks = []\n",
    "# TTps = []\n",
    "# TpTs = []\n",
    "\n",
    "# kappa_fixed = baseMap.genGRF(fKK, test=False)\n",
    "\n",
    "# for s_idx in trange(1):\n",
    "#     #Qu+23 E10\n",
    "#     mapsF = [in_data['cmb0F_1'][s_idx], \n",
    "#             in_data['cmb0F_1'][s_idx+100], \n",
    "#             in_data['cmb0F_1'][s_idx+200],\n",
    "#             in_data['cmb0F_1'][s_idx+300]] \n",
    "#     maps = list(map(baseMap.inverseFourier, mapsF))\n",
    "    \n",
    "#     kappasF = [kappa_fixed,\n",
    "#             kappa_fixed,\n",
    "#             in_data['kCmbF_1'][s_idx],\n",
    "#             in_data['kCmbF_1'][s_idx+100]]\n",
    "    \n",
    "#     #do lensing\n",
    "#     maps = [baseMap.doLensing(cmb0, kappaFourier=kCmbFourier) for cmb0, kCmbFourier in zip(maps, kappasF)]\n",
    "#     mapsF = list(map(baseMap.fourier, maps))\n",
    "    \n",
    "#     #apply foreground and noise\n",
    "#     fgsF  = [in_data['fgF_1'][s_idx], \n",
    "#             in_data['fgF_1'][s_idx+100], \n",
    "#             in_data['fgF_1'][s_idx+200],\n",
    "#             in_data['fgF_1'][s_idx+300]] \n",
    "    \n",
    "#     noisesF =  [in_data['noiseF_1'][s_idx], \n",
    "#             in_data['noiseF_1'][s_idx+100], \n",
    "#             in_data['noiseF_1'][s_idx+200],\n",
    "#             in_data['noiseF_1'][s_idx+300]] \n",
    "    \n",
    "    \n",
    "#     mapsF = [mapF + fgF + noiseF for mapF, fgF, noiseF in zip(mapsF, fgsF, noisesF)]\n",
    "#     maps = list(map(baseMap.inverseFourier, mapsF))\n",
    "    \n",
    "    \n",
    "#     TkTkp = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "#                                          lMin=lMin, lMax=lMax, \n",
    "#                                          dataFourier=mapsF[0],\n",
    "#                                          dataFourier2=mapsF[1])\n",
    "    \n",
    "#     TkpTk = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "#                                          lMin=lMin, lMax=lMax, \n",
    "#                                          dataFourier=mapsF[1],\n",
    "#                                          dataFourier2=mapsF[0])\n",
    "    \n",
    "#     TTp   = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "#                                          lMin=lMin, lMax=lMax, \n",
    "#                                          dataFourier=mapsF[2],\n",
    "#                                          dataFourier2=mapsF[3])\n",
    "    \n",
    "#     TpT   = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "#                                          lMin=lMin, lMax=lMax, \n",
    "#                                          dataFourier=mapsF[3],\n",
    "#                                          dataFourier2=mapsF[2])\n",
    "    \n",
    "\n",
    "#     if(len(TkTkps)==0):\n",
    "#         TkTkps = np.array([TkTkp])\n",
    "#     else:\n",
    "#         TkTkps = np.vstack((TkTkps, np.array([TkTkp])))\n",
    "\n",
    "\n",
    "#     if(len(TkpTks)==0):\n",
    "#         TkpTks = np.array([TkpTk])\n",
    "#     else:\n",
    "#         TkpTks = np.vstack((TkpTks, np.array([TkpTk])))\n",
    "\n",
    "\n",
    "\n",
    "#     if(len(TTps)==0):\n",
    "#         TTps = np.array([TTp])\n",
    "#     else:\n",
    "#         TTps = np.vstack((TTps, np.array([TTp])))\n",
    "        \n",
    "\n",
    "#     if(len(TpTs)==0):\n",
    "#         TpTs = np.array([TpT])\n",
    "#     else:\n",
    "#         TpTs = np.vstack((TpTs, np.array([TpT])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777057e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gets a theoretical prediction for the noise\")\n",
    "fNqCmb_fft = baseMap.forecastN0Kappa(funlensedTT, cmb.fCtotal, lMin=lMin, lMax=lMax, test=False)\n",
    "Ntheory = lambda l: fNqCmb_fft(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "TkTkps = []\n",
    "TkpTks = []\n",
    "TTps = []\n",
    "TpTs = []\n",
    "\n",
    "\n",
    "# Create a manager object\n",
    "manager = multiprocessing.Manager()\n",
    "\n",
    "# Create shared lists using the manager\n",
    "TkTkps = manager.list()\n",
    "TkpTks = manager.list()\n",
    "TTps = manager.list()\n",
    "TpTs = manager.list()\n",
    "\n",
    "# Define a worker function for parallel processing\n",
    "def process_data(s_idx):\n",
    "    global TkTkps\n",
    "    global TkpTks\n",
    "    global TTps\n",
    "    global TpTs\n",
    "\n",
    "    #Qu+23 E10\n",
    "    mapsF = [in_data['cmb0F_1'][s_idx], \n",
    "            in_data['cmb0F_1'][s_idx+100], \n",
    "            in_data['cmb0F_1'][s_idx+200],\n",
    "            in_data['cmb0F_1'][s_idx+300]] \n",
    "    maps = list(map(baseMap.inverseFourier, mapsF))\n",
    "    \n",
    "    kappasF = [in_data['kCmbF_1'][s_idx+200], #commone lensinig potential\n",
    "            in_data['kCmbF_1'][s_idx+200], #commone lensinig potential\n",
    "            in_data['kCmbF_1'][s_idx],\n",
    "            in_data['kCmbF_1'][s_idx+100]]\n",
    "    \n",
    "    #do lensing\n",
    "    maps = [baseMap.doLensing(cmb0, kappaFourier=kappaF) \n",
    "            for cmb0, kappaF in zip(maps, kappasF)]\n",
    "    mapsF = list(map(baseMap.fourier, maps))\n",
    "    \n",
    "    #apply foreground and noise\n",
    "    fgsF  = [in_data['fgF_1'][s_idx], \n",
    "            in_data['fgF_1'][s_idx+100], \n",
    "            in_data['fgF_1'][s_idx+200],\n",
    "            in_data['fgF_1'][s_idx+300]] \n",
    "    \n",
    "    noisesF =  [in_data['noiseF_1'][s_idx], \n",
    "            in_data['noiseF_1'][s_idx+100], \n",
    "            in_data['noiseF_1'][s_idx+200],\n",
    "            in_data['noiseF_1'][s_idx+300]] \n",
    "    \n",
    "    \n",
    "    mapsF = [mapF + fgF + noiseF for mapF, fgF, noiseF in zip(mapsF, fgsF, noisesF)]\n",
    "    maps = list(map(baseMap.inverseFourier, mapsF))\n",
    "    \n",
    "    \n",
    "    TkTkp = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "                                         lMin=lMin, lMax=lMax, \n",
    "                                         dataFourier=mapsF[0],\n",
    "                                         dataFourier2=mapsF[1])\n",
    "    \n",
    "    TkpTk = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "                                         lMin=lMin, lMax=lMax, \n",
    "                                         dataFourier=mapsF[1],\n",
    "                                         dataFourier2=mapsF[0])\n",
    "    \n",
    "    TTp   = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "                                         lMin=lMin, lMax=lMax, \n",
    "                                         dataFourier=mapsF[2],\n",
    "                                         dataFourier2=mapsF[3])\n",
    "    \n",
    "    TpT   = baseMap.computeQuadEstKappaNorm(fTgradT, cmb.fCtotal, \n",
    "                                         lMin=lMin, lMax=lMax, \n",
    "                                         dataFourier=mapsF[3],\n",
    "                                         dataFourier2=mapsF[2])\n",
    "    \n",
    "\n",
    "    TkTkps.append(TkTkp)\n",
    "    TkpTks.append(TkpTk)\n",
    "    TTps.append(TTp)\n",
    "    TpTs.append(TpT)\n",
    "    \n",
    "    \n",
    "# Create a pool of worker processes\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "# Map the worker function to the range of s_idx values\n",
    "results = list(tqdm(pool.imap(process_data,  range(100)), total=100))\n",
    "\n",
    "# Close the pool to indicate that no more tasks will be submitted\n",
    "pool.close()\n",
    "\n",
    "# Wait for all the worker processes to finish\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a41d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(TkTkps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45261dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_combine_Cl(Cls_tot):\n",
    "    n_runs = np.shape(Cls_tot)[0]\n",
    "    lCen = Cls_tot[0][0]\n",
    "    Cls = np.sum(np.transpose(Cls_tot, axes=[1,2,0])[1], axis=1)\n",
    "    sCls = np.sum(np.transpose(Cls_tot, axes=[1,2,0])[2], axis=1)\n",
    "    return lCen, Cls, sCls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905411ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nBins = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a824e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = None\n",
    "ck = 'N1'\n",
    "def compute_data(i, j):\n",
    "    TTp = TTps[i]\n",
    "    TpT = TpTs[i]\n",
    "    TkTkp = TkTkps[j]\n",
    "    TkpTk = TkpTks[j]\n",
    "    curr_data = []\n",
    "\n",
    "    for s, a, b in [[1, TkTkp, TkTkp], [1, TkTkp, TkpTk], [-1, TTp, TTp], [-1, TTp, TpT]]:\n",
    "        t0, t1, t2 = baseMap.crossPowerSpectrum(dataFourier1=a, dataFourier2=b, nBins=nBins)\n",
    "        curr_data.append([t0, s * t1, t2])\n",
    "\n",
    "    c_ps_data = {}\n",
    "    c_ps_data[ck] = [0, 0, 0]\n",
    "    c_ps_data[ck][0], c_ps_data[ck][1], c_ps_data[ck][2] = tmp_combine_Cl(curr_data)\n",
    "    \n",
    "    return c_ps_data[ck]\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "results = []\n",
    "for i in trange(len(TTps)):\n",
    "    for j in range(len(TkTkps)):\n",
    "        results.append(pool.apply_async(compute_data, (i, j)))\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for result in tqdm(results):\n",
    "    if c_data is None:\n",
    "        c_data = np.array([result.get()])\n",
    "    else:\n",
    "        c_data = np.vstack((c_data, np.array([result.get()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f9966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_Cl(Cls_tot):\n",
    "    n_runs = np.shape(Cls_tot)[0]\n",
    "    print(n_runs, np.shape(Cls_tot))\n",
    "    lCen = Cls_tot[0][0]\n",
    "    Cls = np.sum(np.transpose(Cls_tot, axes=[1,2,0])[1], axis=1)/n_runs\n",
    "    sCls = np.sqrt(np.sum(np.square(np.transpose(Cls_tot, axes=[1,2,0])[2]), axis=1))/n_runs\n",
    "    return lCen, Cls, sCls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N1_mcmc = combine_Cl(c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/oak/stanford/orgs/kipac/users/delon/LensQuEst/N1-mcmc-nBins%d.pkl'%(nBins), \"wb\") as f:\n",
    "#     pickle.dump(N1_mcmc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=1, figsize=(10,8))\n",
    "\n",
    "ell = baseMap.l.flatten()\n",
    "theory=[fKK, Ntheory]\n",
    "theory_l=[r'$\\big<\\kappa\\kappa\\big>$', r'$N_{\\rm theory}$']\n",
    "theory_s=['black', 'lightgrey']\n",
    "factor = lambda x : 1\n",
    "for f,l,sty in zip(theory, theory_l, theory_s):\n",
    "    L = np.logspace(np.log10(1.), np.log10(np.max(ell)), 201, 10.)\n",
    "    ClExpected = np.array(list(map(f, L)))\n",
    "    ax.plot(L, factor(L)*ClExpected, sty, label=l)\n",
    "    \n",
    "    \n",
    "n1 = np.loadtxt('n1_data/N1_All_analytical.dat').T    \n",
    "indices = ['TT', 'EE', 'EB', 'TE', 'TB', 'BB']\n",
    "bins = n1[0]\n",
    "n1_mat = np.reshape(n1[1:], (len(indices), len(indices), len(bins)))\n",
    "for i in range(len(indices)):\n",
    "    if(indices[i] != 'TT'):\n",
    "        continue        \n",
    "    n1_pp = (bins*(bins+1))**2/(2*np.pi)*(n1_mat[i][i][:])\n",
    "    KK = fKK(bins)\n",
    "\n",
    "    phiphi =  -2. * KK / bins**2\n",
    "    phiphi *=  -2./ bins**2\n",
    "    phiphi *= (bins*(bins+1))**2/(2*np.pi) #convention from CAMB \n",
    "\n",
    "    pp_n1 = phiphi+n1_pp\n",
    "\n",
    "    KK_n1 = pp_n1 * 2*np.pi / (bins*(bins+1))**2 #back to our convention\n",
    "    KK_n1 *= - bins**2 / 2\n",
    "    KK_n1 *= - bins**2 / 2\n",
    "    plt.plot(bins, KK_n1, 'k--', label=r'$\\big<\\kappa\\kappa\\big>+N^{(1)}$')\n",
    "\n",
    "    \n",
    "lCen, Cl, sCl = N1_mcmc\n",
    "Ipos = np.where(Cl>0)\n",
    "\n",
    "Ineg = np.where(Cl<0)\n",
    "\n",
    "\n",
    "\n",
    "t0, t1 = baseMap.binTheoryPowerSpectrum(fKK, nBins=nBins)\n",
    "t2 = np.zeros_like(t1)\n",
    "\n",
    "\n",
    "ax.errorbar(lCen, (Cl+t1), yerr=sCl, alpha=.75, \n",
    "            fmt='-', capsize=3, capthick=1, label=r'$\\left<\\kappa\\kappa\\right>+N^{(1)}_{\\rm MCMC}$')\n",
    "# ax.errorbar(lCen[Ineg], (Cl[Ipos]+t1[Ineg]), yerr=sCl[Ineg], alpha=.75, \n",
    "#             fmt='--', capsize=3, capthick=1)#, label=r'$\\left<\\kappa\\kappa\\right>+N^{(1)}_{\\rm MCMC}$')\n",
    "\n",
    "ax.set_title('Unmasked')\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(r'$\\ell$')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(lMin,2*lMax)\n",
    "ax.set_ylim(1.1e-10,.9e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2a4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nblensing",
   "language": "python",
   "name": "nblensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
